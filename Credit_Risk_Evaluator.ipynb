{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Evaluator\n",
    "\n",
    "## Supervised machine learning challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config option `kernel_spec_manager_class` not recognized by `EnableNBExtensionApp`.\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: ok\n"
     ]
    }
   ],
   "source": [
    "# !pip install ipywidgets\n",
    "# !pip install --upgrade jupyter_core jupyter_client\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>total_bal_ex_mort</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>total_il_high_credit_limit</th>\n",
       "      <th>hardship_flag</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57107</td>\n",
       "      <td>57107</td>\n",
       "      <td>13375.0</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>483.34</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>223000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>577150.0</td>\n",
       "      <td>122018.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>170200.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141451</td>\n",
       "      <td>141451</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>478.68</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>123000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132750.0</td>\n",
       "      <td>27896.0</td>\n",
       "      <td>15900.0</td>\n",
       "      <td>35398.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321143</td>\n",
       "      <td>321143</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>448.95</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>197000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>85.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>628160.0</td>\n",
       "      <td>114043.0</td>\n",
       "      <td>22600.0</td>\n",
       "      <td>90340.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11778</td>\n",
       "      <td>11778</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>100.22</td>\n",
       "      <td>RENT</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42006.0</td>\n",
       "      <td>20761.0</td>\n",
       "      <td>19900.0</td>\n",
       "      <td>15406.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>169382</td>\n",
       "      <td>169382</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0.1612</td>\n",
       "      <td>1056.49</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>133000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283248.0</td>\n",
       "      <td>109056.0</td>\n",
       "      <td>79500.0</td>\n",
       "      <td>58778.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   index  loan_amnt  int_rate  installment home_ownership  \\\n",
       "0       57107   57107    13375.0    0.1797       483.34       MORTGAGE   \n",
       "1      141451  141451    21000.0    0.1308       478.68       MORTGAGE   \n",
       "2      321143  321143    20000.0    0.1240       448.95       MORTGAGE   \n",
       "3       11778   11778     3000.0    0.1240       100.22           RENT   \n",
       "4      169382  169382    30000.0    0.1612      1056.49       MORTGAGE   \n",
       "\n",
       "   annual_inc verification_status loan_status pymnt_plan  ...  pct_tl_nvr_dlq  \\\n",
       "0    223000.0        Not Verified    low_risk          n  ...           100.0   \n",
       "1    123000.0     Source Verified    low_risk          n  ...            85.0   \n",
       "2    197000.0     Source Verified    low_risk          n  ...            85.7   \n",
       "3     45000.0        Not Verified    low_risk          n  ...           100.0   \n",
       "4    133000.0     Source Verified    low_risk          n  ...           100.0   \n",
       "\n",
       "   percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  tot_hi_cred_lim  \\\n",
       "0              50.0                   0.0        0.0         577150.0   \n",
       "1              33.3                   0.0        0.0         132750.0   \n",
       "2              33.3                   0.0        0.0         628160.0   \n",
       "3              16.7                   1.0        0.0          42006.0   \n",
       "4              66.7                   0.0        0.0         283248.0   \n",
       "\n",
       "   total_bal_ex_mort  total_bc_limit total_il_high_credit_limit  \\\n",
       "0           122018.0         32000.0                   170200.0   \n",
       "1            27896.0         15900.0                    35398.0   \n",
       "2           114043.0         22600.0                    90340.0   \n",
       "3            20761.0         19900.0                    15406.0   \n",
       "4           109056.0         79500.0                    58778.0   \n",
       "\n",
       "   hardship_flag  debt_settlement_flag  \n",
       "0              N                     N  \n",
       "1              N                     N  \n",
       "2              N                     N  \n",
       "3              N                     N  \n",
       "4              N                     N  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the independent variables\n",
    "X_train = train_df.drop(columns=['loan_status'])\n",
    "X_test = test_df.drop(columns=['loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'index', 'loan_amnt', 'int_rate', 'installment',\n",
      "       'annual_inc', 'dti', 'delinq_2yrs', 'inq_last_6mths', 'open_acc',\n",
      "       'pub_rec', 'revol_bal', 'total_acc', 'out_prncp', 'out_prncp_inv',\n",
      "       'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int',\n",
      "       'total_rec_late_fee', 'recoveries', 'collection_recovery_fee',\n",
      "       'last_pymnt_amnt', 'collections_12_mths_ex_med', 'policy_code',\n",
      "       'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m',\n",
      "       'open_act_il', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il',\n",
      "       'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc',\n",
      "       'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m',\n",
      "       'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util',\n",
      "       'chargeoff_within_12_mths', 'delinq_amnt', 'mo_sin_old_il_acct',\n",
      "       'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl',\n",
      "       'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_inq',\n",
      "       'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl',\n",
      "       'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl',\n",
      "       'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m',\n",
      "       'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m',\n",
      "       'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies',\n",
      "       'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
      "       'total_il_high_credit_limit', 'home_ownership_ANY',\n",
      "       'home_ownership_MORTGAGE', 'home_ownership_OWN', 'home_ownership_RENT',\n",
      "       'verification_status_Not Verified',\n",
      "       'verification_status_Source Verified', 'verification_status_Verified',\n",
      "       'pymnt_plan_n', 'initial_list_status_f', 'initial_list_status_w',\n",
      "       'application_type_Individual', 'application_type_Joint App',\n",
      "       'hardship_flag_N', 'hardship_flag_Y', 'debt_settlement_flag_N',\n",
      "       'debt_settlement_flag_Y'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'index', 'loan_amnt', 'int_rate', 'installment',\n",
      "       'annual_inc', 'dti', 'delinq_2yrs', 'inq_last_6mths', 'open_acc',\n",
      "       'pub_rec', 'revol_bal', 'total_acc', 'out_prncp', 'out_prncp_inv',\n",
      "       'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int',\n",
      "       'total_rec_late_fee', 'recoveries', 'collection_recovery_fee',\n",
      "       'last_pymnt_amnt', 'collections_12_mths_ex_med', 'policy_code',\n",
      "       'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m',\n",
      "       'open_act_il', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il',\n",
      "       'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc',\n",
      "       'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m',\n",
      "       'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util',\n",
      "       'chargeoff_within_12_mths', 'delinq_amnt', 'mo_sin_old_il_acct',\n",
      "       'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl',\n",
      "       'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_inq',\n",
      "       'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl',\n",
      "       'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl',\n",
      "       'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m',\n",
      "       'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m',\n",
      "       'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies',\n",
      "       'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
      "       'total_il_high_credit_limit', 'home_ownership_ANY',\n",
      "       'home_ownership_MORTGAGE', 'home_ownership_OWN', 'home_ownership_RENT',\n",
      "       'verification_status_Not Verified',\n",
      "       'verification_status_Source Verified', 'verification_status_Verified',\n",
      "       'pymnt_plan_n', 'initial_list_status_f', 'initial_list_status_w',\n",
      "       'application_type_Individual', 'application_type_Joint App',\n",
      "       'hardship_flag_N', 'hardship_flag_Y', 'debt_settlement_flag_N',\n",
      "       'debt_settlement_flag_Y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical columns to numeric\n",
    "X_train_dummies = pd.get_dummies(X_train)\n",
    "print(X_train_dummies.columns)\n",
    "\n",
    "X_test_dummies = pd.get_dummies(X_test)\n",
    "X_test_dummies['debt_settlement_flag_Y'] = 0 # added to match number of columns with train_df_dummies\n",
    "print(X_test_dummies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dependent variables\n",
    "y_train_label = LabelEncoder().fit_transform(train_df['loan_status'])\n",
    "y_test_label = LabelEncoder().fit_transform(test_df['loan_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction prior to running models (unscaled data)\n",
    "\n",
    "My assumption is that LogisticRegression model will be more accurate for this dataset.  The reason for this is that I believe the columns of data are highly correlated, for example, if one of the columns of data suggests a higher loan risk, then the other columns will also suggest this.  \n",
    "  \n",
    "  My assumption is that LogisticRegression is better for binary, highly correlated datasets and RandomForest method is better for more complex datasets where correlations are not easily identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7008210180623974\n",
      "Testing Data Score: 0.5648660144619311\n"
     ]
    }
   ],
   "source": [
    "# Initialize Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(max_iter=100_000)\n",
    "\n",
    "# Fit the unscaled data\n",
    "classifier.fit(X_train_dummies, y_train_label)\n",
    "\n",
    "# Print the scores of the model on the training and test data sets\n",
    "print(f\"Training Data Score: {classifier.score(X_train_dummies, y_train_label)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test_dummies, y_test_label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9999178981937603\n",
      "Testing Score: 0.6352615908124203\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Classifier model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Fit the data\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=50).fit(X_train_dummies, y_train_label)\n",
    "\n",
    "# Print the scores\n",
    "print(f'Training Score: {clf.score(X_train_dummies, y_train_label)}')\n",
    "print(f'Testing Score: {clf.score(X_test_dummies, y_test_label)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Model Results Analysis (unscaled data)\n",
    "  \n",
    "  After running both the Logistic Regression and Random Forest models, it's clear that for the unscaled data, the Random Forest model is superior to the Logistic Regression model in terms of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data, preprocessing\n",
    "scaler = StandardScaler().fit(X_train_dummies)\n",
    "X_train_scaled = scaler.transform(X_train_dummies)\n",
    "X_test_scaled = scaler.transform(X_test_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction prior to running models (scaled data)\n",
    "  \n",
    "  My prediction is that the scaled models will provide more accurate modeling for the LogisticRegression as the scaled model will be less complex, more regularized.  \n",
    "  \n",
    "  However, for the Random Forest model, I think the results will be unchanged because convergence and precision issues aren't as important for RandomForest as it is for Logistic or Linear regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.712807881773399\n",
      "Testing Data Score: 0.7203317737133135\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Fit the data\n",
    "classifier.fit(X_train_scaled, y_train_label)\n",
    "\n",
    "# Print out the scores\n",
    "print(f\"Training Data Score: {classifier.score(X_train_scaled, y_train_label)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test_scaled, y_test_label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9999178981937603\n",
      "Testing Score: 0.6337728626116547\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Classifier model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Fit the data\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=50).fit(X_train_scaled, y_train_label)\n",
    "\n",
    "# Print out the scores\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train_label)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test_label)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Model Results Analysis (scaled data)\n",
    "  \n",
    "  The Logistic Regression model is superior with scaled data.  \n",
    "  The results of Random Forest using the scaled data are unchanged from the results of the unscaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code used to verify that column names match for each dataframe and to identify any missing columns\n",
    "# train_dummies_column_names = list(train_df_dummies.columns)\n",
    "# train_dummies_df_column_names = pd.DataFrame(train_dummies_column_names)\n",
    "# train_dummies_df_column_names.to_csv('train_df_dummies_column_names.csv')\n",
    "\n",
    "# test_dummies_column_names = list(test_df_dummies.columns)\n",
    "# test_dummies_df_column_names = pd.DataFrame(test_dummies_column_names)\n",
    "# test_dummies_df_column_names.to_csv('test_df_dummies_column_names.csv')\n",
    "\n",
    "# This code used to explore datatypes of train_df and test_df\n",
    "# train_df.info()\n",
    "# test_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv]",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
